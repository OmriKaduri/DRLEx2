{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Reward: 11.0 Average over 100 episodes: 0.0\n",
      "Episode 1 Reward: 32.0 Average over 100 episodes: 0.0\n",
      "Episode 2 Reward: 15.0 Average over 100 episodes: 0.0\n",
      "Episode 3 Reward: 21.0 Average over 100 episodes: 0.0\n",
      "Episode 4 Reward: 9.0 Average over 100 episodes: 0.0\n",
      "Episode 5 Reward: 11.0 Average over 100 episodes: 0.0\n",
      "Episode 6 Reward: 14.0 Average over 100 episodes: 0.0\n",
      "Episode 7 Reward: 17.0 Average over 100 episodes: 0.0\n",
      "Episode 8 Reward: 13.0 Average over 100 episodes: 0.0\n",
      "Episode 9 Reward: 14.0 Average over 100 episodes: 0.0\n",
      "Episode 10 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 11 Reward: 27.0 Average over 100 episodes: 0.0\n",
      "Episode 12 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 13 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 14 Reward: 9.0 Average over 100 episodes: 0.0\n",
      "Episode 15 Reward: 11.0 Average over 100 episodes: 0.0\n",
      "Episode 16 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 17 Reward: 12.0 Average over 100 episodes: 0.0\n",
      "Episode 18 Reward: 20.0 Average over 100 episodes: 0.0\n",
      "Episode 19 Reward: 61.0 Average over 100 episodes: 0.0\n",
      "Episode 20 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 21 Reward: 32.0 Average over 100 episodes: 0.0\n",
      "Episode 22 Reward: 40.0 Average over 100 episodes: 0.0\n",
      "Episode 23 Reward: 15.0 Average over 100 episodes: 0.0\n",
      "Episode 24 Reward: 31.0 Average over 100 episodes: 0.0\n",
      "Episode 25 Reward: 19.0 Average over 100 episodes: 0.0\n",
      "Episode 26 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 27 Reward: 20.0 Average over 100 episodes: 0.0\n",
      "Episode 28 Reward: 26.0 Average over 100 episodes: 0.0\n",
      "Episode 29 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 30 Reward: 23.0 Average over 100 episodes: 0.0\n",
      "Episode 31 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 32 Reward: 29.0 Average over 100 episodes: 0.0\n",
      "Episode 33 Reward: 15.0 Average over 100 episodes: 0.0\n",
      "Episode 34 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 35 Reward: 13.0 Average over 100 episodes: 0.0\n",
      "Episode 36 Reward: 24.0 Average over 100 episodes: 0.0\n",
      "Episode 37 Reward: 21.0 Average over 100 episodes: 0.0\n",
      "Episode 38 Reward: 15.0 Average over 100 episodes: 0.0\n",
      "Episode 39 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 40 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 41 Reward: 26.0 Average over 100 episodes: 0.0\n",
      "Episode 42 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 43 Reward: 22.0 Average over 100 episodes: 0.0\n",
      "Episode 44 Reward: 17.0 Average over 100 episodes: 0.0\n",
      "Episode 45 Reward: 13.0 Average over 100 episodes: 0.0\n",
      "Episode 46 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 47 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 48 Reward: 21.0 Average over 100 episodes: 0.0\n",
      "Episode 49 Reward: 10.0 Average over 100 episodes: 0.0\n",
      "Episode 50 Reward: 21.0 Average over 100 episodes: 0.0\n",
      "Episode 51 Reward: 12.0 Average over 100 episodes: 0.0\n",
      "Episode 52 Reward: 17.0 Average over 100 episodes: 0.0\n",
      "Episode 53 Reward: 23.0 Average over 100 episodes: 0.0\n",
      "Episode 54 Reward: 25.0 Average over 100 episodes: 0.0\n",
      "Episode 55 Reward: 29.0 Average over 100 episodes: 0.0\n",
      "Episode 56 Reward: 14.0 Average over 100 episodes: 0.0\n",
      "Episode 57 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 58 Reward: 32.0 Average over 100 episodes: 0.0\n",
      "Episode 59 Reward: 26.0 Average over 100 episodes: 0.0\n",
      "Episode 60 Reward: 20.0 Average over 100 episodes: 0.0\n",
      "Episode 61 Reward: 15.0 Average over 100 episodes: 0.0\n",
      "Episode 62 Reward: 20.0 Average over 100 episodes: 0.0\n",
      "Episode 63 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 64 Reward: 24.0 Average over 100 episodes: 0.0\n",
      "Episode 65 Reward: 31.0 Average over 100 episodes: 0.0\n",
      "Episode 66 Reward: 19.0 Average over 100 episodes: 0.0\n",
      "Episode 67 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 68 Reward: 29.0 Average over 100 episodes: 0.0\n",
      "Episode 69 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 70 Reward: 22.0 Average over 100 episodes: 0.0\n",
      "Episode 71 Reward: 23.0 Average over 100 episodes: 0.0\n",
      "Episode 72 Reward: 9.0 Average over 100 episodes: 0.0\n",
      "Episode 73 Reward: 16.0 Average over 100 episodes: 0.0\n",
      "Episode 74 Reward: 19.0 Average over 100 episodes: 0.0\n",
      "Episode 75 Reward: 54.0 Average over 100 episodes: 0.0\n",
      "Episode 76 Reward: 63.0 Average over 100 episodes: 0.0\n",
      "Episode 77 Reward: 14.0 Average over 100 episodes: 0.0\n",
      "Episode 78 Reward: 35.0 Average over 100 episodes: 0.0\n",
      "Episode 79 Reward: 50.0 Average over 100 episodes: 0.0\n",
      "Episode 80 Reward: 24.0 Average over 100 episodes: 0.0\n",
      "Episode 81 Reward: 42.0 Average over 100 episodes: 0.0\n",
      "Episode 82 Reward: 30.0 Average over 100 episodes: 0.0\n",
      "Episode 83 Reward: 20.0 Average over 100 episodes: 0.0\n",
      "Episode 84 Reward: 22.0 Average over 100 episodes: 0.0\n",
      "Episode 85 Reward: 12.0 Average over 100 episodes: 0.0\n",
      "Episode 86 Reward: 29.0 Average over 100 episodes: 0.0\n",
      "Episode 87 Reward: 13.0 Average over 100 episodes: 0.0\n",
      "Episode 88 Reward: 12.0 Average over 100 episodes: 0.0\n",
      "Episode 89 Reward: 34.0 Average over 100 episodes: 0.0\n",
      "Episode 90 Reward: 19.0 Average over 100 episodes: 0.0\n",
      "Episode 91 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 92 Reward: 25.0 Average over 100 episodes: 0.0\n",
      "Episode 93 Reward: 14.0 Average over 100 episodes: 0.0\n",
      "Episode 94 Reward: 19.0 Average over 100 episodes: 0.0\n",
      "Episode 95 Reward: 18.0 Average over 100 episodes: 0.0\n",
      "Episode 96 Reward: 33.0 Average over 100 episodes: 0.0\n",
      "Episode 97 Reward: 26.0 Average over 100 episodes: 0.0\n",
      "Episode 98 Reward: 19.0 Average over 100 episodes: 0.0\n",
      "Episode 99 Reward: 32.0 Average over 100 episodes: 21.16\n",
      "Episode 100 Reward: 27.0 Average over 100 episodes: 21.32\n",
      "Episode 101 Reward: 23.0 Average over 100 episodes: 21.23\n",
      "Episode 102 Reward: 34.0 Average over 100 episodes: 21.42\n",
      "Episode 103 Reward: 19.0 Average over 100 episodes: 21.4\n",
      "Episode 104 Reward: 54.0 Average over 100 episodes: 21.85\n",
      "Episode 105 Reward: 14.0 Average over 100 episodes: 21.88\n",
      "Episode 106 Reward: 26.0 Average over 100 episodes: 22.0\n",
      "Episode 107 Reward: 37.0 Average over 100 episodes: 22.2\n",
      "Episode 108 Reward: 23.0 Average over 100 episodes: 22.3\n",
      "Episode 109 Reward: 29.0 Average over 100 episodes: 22.45\n",
      "Episode 110 Reward: 21.0 Average over 100 episodes: 22.5\n",
      "Episode 111 Reward: 47.0 Average over 100 episodes: 22.7\n",
      "Episode 112 Reward: 26.0 Average over 100 episodes: 22.86\n",
      "Episode 113 Reward: 15.0 Average over 100 episodes: 22.85\n",
      "Episode 114 Reward: 30.0 Average over 100 episodes: 23.06\n",
      "Episode 115 Reward: 38.0 Average over 100 episodes: 23.33\n",
      "Episode 116 Reward: 57.0 Average over 100 episodes: 23.72\n",
      "Episode 117 Reward: 19.0 Average over 100 episodes: 23.79\n",
      "Episode 118 Reward: 15.0 Average over 100 episodes: 23.74\n",
      "Episode 119 Reward: 16.0 Average over 100 episodes: 23.29\n",
      "Episode 120 Reward: 23.0 Average over 100 episodes: 23.36\n",
      "Episode 121 Reward: 42.0 Average over 100 episodes: 23.46\n",
      "Episode 122 Reward: 24.0 Average over 100 episodes: 23.3\n",
      "Episode 123 Reward: 21.0 Average over 100 episodes: 23.36\n",
      "Episode 124 Reward: 19.0 Average over 100 episodes: 23.24\n",
      "Episode 125 Reward: 22.0 Average over 100 episodes: 23.27\n",
      "Episode 126 Reward: 23.0 Average over 100 episodes: 23.34\n",
      "Episode 127 Reward: 15.0 Average over 100 episodes: 23.29\n",
      "Episode 128 Reward: 19.0 Average over 100 episodes: 23.22\n",
      "Episode 129 Reward: 23.0 Average over 100 episodes: 23.35\n",
      "Episode 130 Reward: 17.0 Average over 100 episodes: 23.29\n",
      "Episode 131 Reward: 32.0 Average over 100 episodes: 23.51\n",
      "Episode 132 Reward: 11.0 Average over 100 episodes: 23.33\n",
      "Episode 133 Reward: 25.0 Average over 100 episodes: 23.43\n",
      "Episode 134 Reward: 18.0 Average over 100 episodes: 23.45\n",
      "Episode 135 Reward: 20.0 Average over 100 episodes: 23.52\n",
      "Episode 136 Reward: 23.0 Average over 100 episodes: 23.51\n",
      "Episode 137 Reward: 17.0 Average over 100 episodes: 23.47\n",
      "Episode 138 Reward: 30.0 Average over 100 episodes: 23.62\n",
      "Episode 139 Reward: 18.0 Average over 100 episodes: 23.62\n",
      "Episode 140 Reward: 21.0 Average over 100 episodes: 23.73\n",
      "Episode 141 Reward: 32.0 Average over 100 episodes: 23.79\n",
      "Episode 142 Reward: 63.0 Average over 100 episodes: 24.32\n",
      "Episode 143 Reward: 11.0 Average over 100 episodes: 24.21\n",
      "Episode 144 Reward: 12.0 Average over 100 episodes: 24.16\n",
      "Episode 145 Reward: 47.0 Average over 100 episodes: 24.5\n",
      "Episode 146 Reward: 27.0 Average over 100 episodes: 24.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 147 Reward: 17.0 Average over 100 episodes: 24.66\n",
      "Episode 148 Reward: 23.0 Average over 100 episodes: 24.68\n",
      "Episode 149 Reward: 41.0 Average over 100 episodes: 24.99\n",
      "Episode 150 Reward: 29.0 Average over 100 episodes: 25.07\n",
      "Episode 151 Reward: 37.0 Average over 100 episodes: 25.32\n",
      "Episode 152 Reward: 43.0 Average over 100 episodes: 25.58\n",
      "Episode 153 Reward: 34.0 Average over 100 episodes: 25.69\n",
      "Episode 154 Reward: 67.0 Average over 100 episodes: 26.11\n",
      "Episode 155 Reward: 14.0 Average over 100 episodes: 25.96\n",
      "Episode 156 Reward: 68.0 Average over 100 episodes: 26.5\n",
      "Episode 157 Reward: 25.0 Average over 100 episodes: 26.59\n",
      "Episode 158 Reward: 16.0 Average over 100 episodes: 26.43\n",
      "Episode 159 Reward: 45.0 Average over 100 episodes: 26.62\n",
      "Episode 160 Reward: 31.0 Average over 100 episodes: 26.73\n",
      "Episode 161 Reward: 17.0 Average over 100 episodes: 26.75\n",
      "Episode 162 Reward: 11.0 Average over 100 episodes: 26.66\n",
      "Episode 163 Reward: 32.0 Average over 100 episodes: 26.8\n",
      "Episode 164 Reward: 9.0 Average over 100 episodes: 26.65\n",
      "Episode 165 Reward: 54.0 Average over 100 episodes: 26.88\n",
      "Episode 166 Reward: 34.0 Average over 100 episodes: 27.03\n",
      "Episode 167 Reward: 39.0 Average over 100 episodes: 27.24\n",
      "Episode 168 Reward: 52.0 Average over 100 episodes: 27.47\n",
      "Episode 169 Reward: 32.0 Average over 100 episodes: 27.61\n",
      "Episode 170 Reward: 33.0 Average over 100 episodes: 27.72\n",
      "Episode 171 Reward: 14.0 Average over 100 episodes: 27.63\n",
      "Episode 172 Reward: 50.0 Average over 100 episodes: 28.04\n",
      "Episode 173 Reward: 12.0 Average over 100 episodes: 28.0\n",
      "Episode 174 Reward: 33.0 Average over 100 episodes: 28.14\n",
      "Episode 175 Reward: 16.0 Average over 100 episodes: 27.76\n",
      "Episode 176 Reward: 15.0 Average over 100 episodes: 27.28\n",
      "Episode 177 Reward: 33.0 Average over 100 episodes: 27.47\n",
      "Episode 178 Reward: 53.0 Average over 100 episodes: 27.65\n",
      "Episode 179 Reward: 39.0 Average over 100 episodes: 27.54\n",
      "Episode 180 Reward: 19.0 Average over 100 episodes: 27.49\n",
      "Episode 181 Reward: 23.0 Average over 100 episodes: 27.3\n",
      "Episode 182 Reward: 32.0 Average over 100 episodes: 27.32\n",
      "Episode 183 Reward: 35.0 Average over 100 episodes: 27.47\n",
      "Episode 184 Reward: 42.0 Average over 100 episodes: 27.67\n",
      "Episode 185 Reward: 51.0 Average over 100 episodes: 28.06\n",
      "Episode 186 Reward: 57.0 Average over 100 episodes: 28.34\n",
      "Episode 187 Reward: 24.0 Average over 100 episodes: 28.45\n",
      "Episode 188 Reward: 34.0 Average over 100 episodes: 28.67\n",
      "Episode 189 Reward: 35.0 Average over 100 episodes: 28.68\n",
      "Episode 190 Reward: 12.0 Average over 100 episodes: 28.61\n",
      "Episode 191 Reward: 33.0 Average over 100 episodes: 28.76\n",
      "Episode 192 Reward: 25.0 Average over 100 episodes: 28.76\n",
      "Episode 193 Reward: 30.0 Average over 100 episodes: 28.92\n",
      "Episode 194 Reward: 39.0 Average over 100 episodes: 29.12\n",
      "Episode 195 Reward: 29.0 Average over 100 episodes: 29.23\n",
      "Episode 196 Reward: 28.0 Average over 100 episodes: 29.18\n",
      "Episode 197 Reward: 33.0 Average over 100 episodes: 29.25\n",
      "Episode 198 Reward: 44.0 Average over 100 episodes: 29.5\n",
      "Episode 199 Reward: 31.0 Average over 100 episodes: 29.49\n",
      "Episode 200 Reward: 166.0 Average over 100 episodes: 30.88\n",
      "Episode 201 Reward: 29.0 Average over 100 episodes: 30.94\n",
      "Episode 202 Reward: 25.0 Average over 100 episodes: 30.85\n",
      "Episode 203 Reward: 26.0 Average over 100 episodes: 30.92\n",
      "Episode 204 Reward: 50.0 Average over 100 episodes: 30.88\n",
      "Episode 205 Reward: 75.0 Average over 100 episodes: 31.49\n",
      "Episode 206 Reward: 50.0 Average over 100 episodes: 31.73\n",
      "Episode 207 Reward: 97.0 Average over 100 episodes: 32.33\n",
      "Episode 208 Reward: 68.0 Average over 100 episodes: 32.78\n",
      "Episode 209 Reward: 44.0 Average over 100 episodes: 32.93\n",
      "Episode 210 Reward: 75.0 Average over 100 episodes: 33.47\n",
      "Episode 211 Reward: 23.0 Average over 100 episodes: 33.23\n",
      "Episode 212 Reward: 48.0 Average over 100 episodes: 33.45\n",
      "Episode 213 Reward: 36.0 Average over 100 episodes: 33.66\n",
      "Episode 214 Reward: 39.0 Average over 100 episodes: 33.75\n",
      "Episode 215 Reward: 61.0 Average over 100 episodes: 33.98\n",
      "Episode 216 Reward: 14.0 Average over 100 episodes: 33.55\n",
      "Episode 217 Reward: 25.0 Average over 100 episodes: 33.61\n",
      "Episode 218 Reward: 18.0 Average over 100 episodes: 33.64\n",
      "Episode 219 Reward: 35.0 Average over 100 episodes: 33.83\n",
      "Episode 220 Reward: 28.0 Average over 100 episodes: 33.88\n",
      "Episode 221 Reward: 14.0 Average over 100 episodes: 33.6\n",
      "Episode 222 Reward: 34.0 Average over 100 episodes: 33.7\n",
      "Episode 223 Reward: 40.0 Average over 100 episodes: 33.89\n",
      "Episode 224 Reward: 30.0 Average over 100 episodes: 34.0\n",
      "Episode 225 Reward: 23.0 Average over 100 episodes: 34.01\n",
      "Episode 226 Reward: 162.0 Average over 100 episodes: 35.4\n",
      "Episode 227 Reward: 24.0 Average over 100 episodes: 35.49\n",
      "Episode 228 Reward: 44.0 Average over 100 episodes: 35.74\n",
      "Episode 229 Reward: 14.0 Average over 100 episodes: 35.65\n",
      "Episode 230 Reward: 49.0 Average over 100 episodes: 35.97\n",
      "Episode 231 Reward: 62.0 Average over 100 episodes: 36.27\n",
      "Episode 232 Reward: 36.0 Average over 100 episodes: 36.52\n",
      "Episode 233 Reward: 52.0 Average over 100 episodes: 36.79\n",
      "Episode 234 Reward: 37.0 Average over 100 episodes: 36.98\n",
      "Episode 235 Reward: 31.0 Average over 100 episodes: 37.09\n",
      "Episode 236 Reward: 101.0 Average over 100 episodes: 37.87\n",
      "Episode 237 Reward: 18.0 Average over 100 episodes: 37.88\n",
      "Episode 238 Reward: 47.0 Average over 100 episodes: 38.05\n",
      "Episode 239 Reward: 55.0 Average over 100 episodes: 38.42\n",
      "Episode 240 Reward: 34.0 Average over 100 episodes: 38.55\n",
      "Episode 241 Reward: 49.0 Average over 100 episodes: 38.72\n",
      "Episode 242 Reward: 44.0 Average over 100 episodes: 38.53\n",
      "Episode 243 Reward: 83.0 Average over 100 episodes: 39.25\n",
      "Episode 244 Reward: 88.0 Average over 100 episodes: 40.01\n",
      "Episode 245 Reward: 55.0 Average over 100 episodes: 40.09\n",
      "Episode 246 Reward: 40.0 Average over 100 episodes: 40.22\n",
      "Episode 247 Reward: 18.0 Average over 100 episodes: 40.23\n",
      "Episode 248 Reward: 94.0 Average over 100 episodes: 40.94\n",
      "Episode 249 Reward: 47.0 Average over 100 episodes: 41.0\n",
      "Episode 250 Reward: 29.0 Average over 100 episodes: 41.0\n",
      "Episode 251 Reward: 25.0 Average over 100 episodes: 40.88\n",
      "Episode 252 Reward: 28.0 Average over 100 episodes: 40.73\n",
      "Episode 253 Reward: 140.0 Average over 100 episodes: 41.79\n",
      "Episode 254 Reward: 43.0 Average over 100 episodes: 41.55\n",
      "Episode 255 Reward: 57.0 Average over 100 episodes: 41.98\n",
      "Episode 256 Reward: 61.0 Average over 100 episodes: 41.91\n",
      "Episode 257 Reward: 18.0 Average over 100 episodes: 41.84\n",
      "Episode 258 Reward: 44.0 Average over 100 episodes: 42.12\n",
      "Episode 259 Reward: 23.0 Average over 100 episodes: 41.9\n",
      "Episode 260 Reward: 35.0 Average over 100 episodes: 41.94\n",
      "Episode 261 Reward: 61.0 Average over 100 episodes: 42.38\n",
      "Episode 262 Reward: 50.0 Average over 100 episodes: 42.77\n",
      "Episode 263 Reward: 87.0 Average over 100 episodes: 43.32\n",
      "Episode 264 Reward: 58.0 Average over 100 episodes: 43.81\n",
      "Episode 265 Reward: 34.0 Average over 100 episodes: 43.61\n",
      "Episode 266 Reward: 38.0 Average over 100 episodes: 43.65\n",
      "Episode 267 Reward: 57.0 Average over 100 episodes: 43.83\n",
      "Episode 268 Reward: 97.0 Average over 100 episodes: 44.28\n",
      "Episode 269 Reward: 36.0 Average over 100 episodes: 44.32\n",
      "Episode 270 Reward: 58.0 Average over 100 episodes: 44.57\n",
      "Episode 271 Reward: 24.0 Average over 100 episodes: 44.67\n",
      "Episode 272 Reward: 30.0 Average over 100 episodes: 44.47\n",
      "Episode 273 Reward: 26.0 Average over 100 episodes: 44.61\n",
      "Episode 274 Reward: 27.0 Average over 100 episodes: 44.55\n",
      "Episode 275 Reward: 63.0 Average over 100 episodes: 45.02\n",
      "Episode 276 Reward: 147.0 Average over 100 episodes: 46.34\n",
      "Episode 277 Reward: 35.0 Average over 100 episodes: 46.36\n",
      "Episode 278 Reward: 42.0 Average over 100 episodes: 46.25\n",
      "Episode 279 Reward: 40.0 Average over 100 episodes: 46.26\n",
      "Episode 280 Reward: 58.0 Average over 100 episodes: 46.65\n",
      "Episode 281 Reward: 26.0 Average over 100 episodes: 46.68\n",
      "Episode 282 Reward: 48.0 Average over 100 episodes: 46.84\n",
      "Episode 283 Reward: 44.0 Average over 100 episodes: 46.93\n",
      "Episode 284 Reward: 36.0 Average over 100 episodes: 46.87\n",
      "Episode 285 Reward: 51.0 Average over 100 episodes: 46.87\n",
      "Episode 286 Reward: 18.0 Average over 100 episodes: 46.48\n",
      "Episode 287 Reward: 14.0 Average over 100 episodes: 46.38\n",
      "Episode 288 Reward: 59.0 Average over 100 episodes: 46.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 289 Reward: 39.0 Average over 100 episodes: 46.67\n",
      "Episode 290 Reward: 34.0 Average over 100 episodes: 46.89\n",
      "Episode 291 Reward: 64.0 Average over 100 episodes: 47.2\n",
      "Episode 292 Reward: 32.0 Average over 100 episodes: 47.27\n",
      "Episode 293 Reward: 61.0 Average over 100 episodes: 47.58\n",
      "Episode 294 Reward: 41.0 Average over 100 episodes: 47.6\n",
      "Episode 295 Reward: 28.0 Average over 100 episodes: 47.59\n",
      "Episode 296 Reward: 33.0 Average over 100 episodes: 47.64\n",
      "Episode 297 Reward: 45.0 Average over 100 episodes: 47.76\n",
      "Episode 298 Reward: 39.0 Average over 100 episodes: 47.71\n",
      "Episode 299 Reward: 12.0 Average over 100 episodes: 47.52\n",
      "Episode 300 Reward: 45.0 Average over 100 episodes: 46.31\n",
      "Episode 301 Reward: 44.0 Average over 100 episodes: 46.46\n",
      "Episode 302 Reward: 59.0 Average over 100 episodes: 46.8\n",
      "Episode 303 Reward: 46.0 Average over 100 episodes: 47.0\n",
      "Episode 304 Reward: 79.0 Average over 100 episodes: 47.29\n",
      "Episode 305 Reward: 22.0 Average over 100 episodes: 46.76\n",
      "Episode 306 Reward: 42.0 Average over 100 episodes: 46.68\n",
      "Episode 307 Reward: 47.0 Average over 100 episodes: 46.18\n",
      "Episode 308 Reward: 29.0 Average over 100 episodes: 45.79\n",
      "Episode 309 Reward: 31.0 Average over 100 episodes: 45.66\n",
      "Episode 310 Reward: 45.0 Average over 100 episodes: 45.36\n",
      "Episode 311 Reward: 46.0 Average over 100 episodes: 45.59\n",
      "Episode 312 Reward: 67.0 Average over 100 episodes: 45.78\n",
      "Episode 313 Reward: 51.0 Average over 100 episodes: 45.93\n",
      "Episode 314 Reward: 67.0 Average over 100 episodes: 46.21\n",
      "Episode 315 Reward: 52.0 Average over 100 episodes: 46.12\n",
      "Episode 316 Reward: 43.0 Average over 100 episodes: 46.41\n",
      "Episode 317 Reward: 53.0 Average over 100 episodes: 46.69\n",
      "Episode 318 Reward: 41.0 Average over 100 episodes: 46.92\n",
      "Episode 319 Reward: 51.0 Average over 100 episodes: 47.08\n",
      "Episode 320 Reward: 32.0 Average over 100 episodes: 47.12\n",
      "Episode 321 Reward: 31.0 Average over 100 episodes: 47.29\n",
      "Episode 322 Reward: 39.0 Average over 100 episodes: 47.34\n",
      "Episode 323 Reward: 33.0 Average over 100 episodes: 47.27\n",
      "Episode 324 Reward: 64.0 Average over 100 episodes: 47.61\n",
      "Episode 325 Reward: 48.0 Average over 100 episodes: 47.86\n",
      "Episode 326 Reward: 58.0 Average over 100 episodes: 46.82\n",
      "Episode 327 Reward: 41.0 Average over 100 episodes: 46.99\n",
      "Episode 328 Reward: 85.0 Average over 100 episodes: 47.4\n",
      "Episode 329 Reward: 44.0 Average over 100 episodes: 47.7\n",
      "Episode 330 Reward: 32.0 Average over 100 episodes: 47.53\n",
      "Episode 331 Reward: 99.0 Average over 100 episodes: 47.9\n",
      "Episode 332 Reward: 53.0 Average over 100 episodes: 48.07\n",
      "Episode 333 Reward: 33.0 Average over 100 episodes: 47.88\n",
      "Episode 334 Reward: 62.0 Average over 100 episodes: 48.13\n",
      "Episode 335 Reward: 25.0 Average over 100 episodes: 48.07\n",
      "Episode 336 Reward: 76.0 Average over 100 episodes: 47.82\n",
      "Episode 337 Reward: 47.0 Average over 100 episodes: 48.11\n",
      "Episode 338 Reward: 126.0 Average over 100 episodes: 48.9\n",
      "Episode 339 Reward: 51.0 Average over 100 episodes: 48.86\n",
      "Episode 340 Reward: 81.0 Average over 100 episodes: 49.33\n",
      "Episode 341 Reward: 43.0 Average over 100 episodes: 49.27\n",
      "Episode 342 Reward: 58.0 Average over 100 episodes: 49.41\n",
      "Episode 343 Reward: 113.0 Average over 100 episodes: 49.71\n",
      "Episode 344 Reward: 68.0 Average over 100 episodes: 49.51\n",
      "Episode 345 Reward: 47.0 Average over 100 episodes: 49.43\n",
      "Episode 346 Reward: 34.0 Average over 100 episodes: 49.37\n",
      "Episode 347 Reward: 43.0 Average over 100 episodes: 49.62\n",
      "Episode 348 Reward: 37.0 Average over 100 episodes: 49.05\n",
      "Episode 349 Reward: 60.0 Average over 100 episodes: 49.18\n",
      "Episode 350 Reward: 85.0 Average over 100 episodes: 49.74\n",
      "Episode 351 Reward: 72.0 Average over 100 episodes: 50.21\n",
      "Episode 352 Reward: 53.0 Average over 100 episodes: 50.46\n",
      "Episode 353 Reward: 50.0 Average over 100 episodes: 49.56\n",
      "Episode 354 Reward: 203.0 Average over 100 episodes: 51.16\n",
      "Episode 355 Reward: 63.0 Average over 100 episodes: 51.22\n",
      "Episode 356 Reward: 31.0 Average over 100 episodes: 50.92\n",
      "Episode 357 Reward: 82.0 Average over 100 episodes: 51.56\n",
      "Episode 358 Reward: 61.0 Average over 100 episodes: 51.73\n",
      "Episode 359 Reward: 17.0 Average over 100 episodes: 51.67\n",
      "Episode 360 Reward: 78.0 Average over 100 episodes: 52.1\n",
      "Episode 361 Reward: 47.0 Average over 100 episodes: 51.96\n",
      "Episode 362 Reward: 59.0 Average over 100 episodes: 52.05\n",
      "Episode 363 Reward: 48.0 Average over 100 episodes: 51.66\n",
      "Episode 364 Reward: 42.0 Average over 100 episodes: 51.5\n",
      "Episode 365 Reward: 32.0 Average over 100 episodes: 51.48\n",
      "Episode 366 Reward: 74.0 Average over 100 episodes: 51.84\n",
      "Episode 367 Reward: 26.0 Average over 100 episodes: 51.53\n",
      "Episode 368 Reward: 52.0 Average over 100 episodes: 51.08\n",
      "Episode 369 Reward: 50.0 Average over 100 episodes: 51.22\n",
      "Episode 370 Reward: 51.0 Average over 100 episodes: 51.15\n",
      "Episode 371 Reward: 47.0 Average over 100 episodes: 51.38\n",
      "Episode 372 Reward: 85.0 Average over 100 episodes: 51.93\n",
      "Episode 373 Reward: 30.0 Average over 100 episodes: 51.97\n",
      "Episode 374 Reward: 18.0 Average over 100 episodes: 51.88\n",
      "Episode 375 Reward: 48.0 Average over 100 episodes: 51.73\n",
      "Episode 376 Reward: 46.0 Average over 100 episodes: 50.72\n",
      "Episode 377 Reward: 49.0 Average over 100 episodes: 50.86\n",
      "Episode 378 Reward: 98.0 Average over 100 episodes: 51.42\n",
      "Episode 379 Reward: 54.0 Average over 100 episodes: 51.56\n",
      "Episode 380 Reward: 161.0 Average over 100 episodes: 52.59\n",
      "Episode 381 Reward: 63.0 Average over 100 episodes: 52.96\n",
      "Episode 382 Reward: 31.0 Average over 100 episodes: 52.79\n",
      "Episode 383 Reward: 32.0 Average over 100 episodes: 52.67\n",
      "Episode 384 Reward: 93.0 Average over 100 episodes: 53.24\n",
      "Episode 385 Reward: 50.0 Average over 100 episodes: 53.23\n",
      "Episode 386 Reward: 59.0 Average over 100 episodes: 53.64\n",
      "Episode 387 Reward: 55.0 Average over 100 episodes: 54.05\n",
      "Episode 388 Reward: 41.0 Average over 100 episodes: 53.87\n",
      "Episode 389 Reward: 108.0 Average over 100 episodes: 54.56\n",
      "Episode 390 Reward: 70.0 Average over 100 episodes: 54.92\n",
      "Episode 391 Reward: 154.0 Average over 100 episodes: 55.82\n",
      "Episode 392 Reward: 29.0 Average over 100 episodes: 55.79\n",
      "Episode 393 Reward: 87.0 Average over 100 episodes: 56.05\n",
      "Episode 394 Reward: 31.0 Average over 100 episodes: 55.95\n",
      "Episode 395 Reward: 47.0 Average over 100 episodes: 56.14\n",
      "Episode 396 Reward: 67.0 Average over 100 episodes: 56.48\n",
      "Episode 397 Reward: 173.0 Average over 100 episodes: 57.76\n",
      "Episode 398 Reward: 42.0 Average over 100 episodes: 57.79\n",
      "Episode 399 Reward: 123.0 Average over 100 episodes: 58.9\n",
      "Episode 400 Reward: 34.0 Average over 100 episodes: 58.79\n",
      "Episode 401 Reward: 163.0 Average over 100 episodes: 59.98\n",
      "Episode 402 Reward: 50.0 Average over 100 episodes: 59.89\n",
      "Episode 403 Reward: 49.0 Average over 100 episodes: 59.92\n",
      "Episode 404 Reward: 17.0 Average over 100 episodes: 59.3\n",
      "Episode 405 Reward: 58.0 Average over 100 episodes: 59.66\n",
      "Episode 406 Reward: 52.0 Average over 100 episodes: 59.76\n",
      "Episode 407 Reward: 179.0 Average over 100 episodes: 61.08\n",
      "Episode 408 Reward: 58.0 Average over 100 episodes: 61.37\n",
      "Episode 409 Reward: 40.0 Average over 100 episodes: 61.46\n",
      "Episode 410 Reward: 45.0 Average over 100 episodes: 61.46\n",
      "Episode 411 Reward: 53.0 Average over 100 episodes: 61.53\n",
      "Episode 412 Reward: 137.0 Average over 100 episodes: 62.23\n",
      "Episode 413 Reward: 55.0 Average over 100 episodes: 62.27\n",
      "Episode 414 Reward: 119.0 Average over 100 episodes: 62.79\n",
      "Episode 415 Reward: 56.0 Average over 100 episodes: 62.83\n",
      "Episode 416 Reward: 82.0 Average over 100 episodes: 63.22\n",
      "Episode 417 Reward: 80.0 Average over 100 episodes: 63.49\n",
      "Episode 418 Reward: 30.0 Average over 100 episodes: 63.38\n",
      "Episode 419 Reward: 68.0 Average over 100 episodes: 63.55\n",
      "Episode 420 Reward: 114.0 Average over 100 episodes: 64.37\n",
      "Episode 421 Reward: 84.0 Average over 100 episodes: 64.9\n",
      "Episode 422 Reward: 120.0 Average over 100 episodes: 65.71\n",
      "Episode 423 Reward: 52.0 Average over 100 episodes: 65.9\n",
      "Episode 424 Reward: 48.0 Average over 100 episodes: 65.74\n",
      "Episode 425 Reward: 71.0 Average over 100 episodes: 65.97\n",
      "Episode 426 Reward: 53.0 Average over 100 episodes: 65.92\n",
      "Episode 427 Reward: 204.0 Average over 100 episodes: 67.55\n",
      "Episode 428 Reward: 95.0 Average over 100 episodes: 67.65\n",
      "Episode 429 Reward: 61.0 Average over 100 episodes: 67.82\n",
      "Episode 430 Reward: 96.0 Average over 100 episodes: 68.46\n",
      "Episode 431 Reward: 61.0 Average over 100 episodes: 68.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 432 Reward: 147.0 Average over 100 episodes: 69.02\n",
      "Episode 433 Reward: 65.0 Average over 100 episodes: 69.34\n",
      "Episode 434 Reward: 109.0 Average over 100 episodes: 69.81\n",
      "Episode 435 Reward: 97.0 Average over 100 episodes: 70.53\n",
      "Episode 436 Reward: 82.0 Average over 100 episodes: 70.59\n",
      "Episode 437 Reward: 80.0 Average over 100 episodes: 70.92\n",
      "Episode 438 Reward: 81.0 Average over 100 episodes: 70.47\n",
      "Episode 439 Reward: 49.0 Average over 100 episodes: 70.45\n",
      "Episode 440 Reward: 189.0 Average over 100 episodes: 71.53\n",
      "Episode 441 Reward: 49.0 Average over 100 episodes: 71.59\n",
      "Episode 442 Reward: 71.0 Average over 100 episodes: 71.72\n",
      "Episode 443 Reward: 231.0 Average over 100 episodes: 72.9\n",
      "Episode 444 Reward: 88.0 Average over 100 episodes: 73.1\n",
      "Episode 445 Reward: 100.0 Average over 100 episodes: 73.63\n",
      "Episode 446 Reward: 175.0 Average over 100 episodes: 75.04\n",
      "Episode 447 Reward: 77.0 Average over 100 episodes: 75.38\n",
      "Episode 448 Reward: 61.0 Average over 100 episodes: 75.62\n",
      "Episode 449 Reward: 103.0 Average over 100 episodes: 76.05\n",
      "Episode 450 Reward: 89.0 Average over 100 episodes: 76.09\n",
      "Episode 451 Reward: 122.0 Average over 100 episodes: 76.59\n",
      "Episode 452 Reward: 144.0 Average over 100 episodes: 77.5\n",
      "Episode 453 Reward: 220.0 Average over 100 episodes: 79.2\n",
      "Episode 454 Reward: 126.0 Average over 100 episodes: 78.43\n",
      "Episode 455 Reward: 116.0 Average over 100 episodes: 78.96\n",
      "Episode 456 Reward: 132.0 Average over 100 episodes: 79.97\n",
      "Episode 457 Reward: 132.0 Average over 100 episodes: 80.47\n",
      "Episode 458 Reward: 88.0 Average over 100 episodes: 80.74\n",
      "Episode 459 Reward: 99.0 Average over 100 episodes: 81.56\n",
      "Episode 460 Reward: 110.0 Average over 100 episodes: 81.88\n",
      "Episode 461 Reward: 101.0 Average over 100 episodes: 82.42\n",
      "Episode 462 Reward: 139.0 Average over 100 episodes: 83.22\n",
      "Episode 463 Reward: 142.0 Average over 100 episodes: 84.16\n",
      "Episode 464 Reward: 89.0 Average over 100 episodes: 84.63\n",
      "Episode 465 Reward: 128.0 Average over 100 episodes: 85.59\n",
      "Episode 466 Reward: 72.0 Average over 100 episodes: 85.57\n",
      "Episode 467 Reward: 250.0 Average over 100 episodes: 87.81\n",
      "Episode 468 Reward: 43.0 Average over 100 episodes: 87.72\n",
      "Episode 469 Reward: 188.0 Average over 100 episodes: 89.1\n",
      "Episode 470 Reward: 127.0 Average over 100 episodes: 89.86\n",
      "Episode 471 Reward: 132.0 Average over 100 episodes: 90.71\n",
      "Episode 472 Reward: 186.0 Average over 100 episodes: 91.72\n",
      "Episode 473 Reward: 164.0 Average over 100 episodes: 93.06\n",
      "Episode 474 Reward: 111.0 Average over 100 episodes: 93.99\n",
      "Episode 475 Reward: 106.0 Average over 100 episodes: 94.57\n",
      "Episode 476 Reward: 77.0 Average over 100 episodes: 94.88\n",
      "Episode 477 Reward: 143.0 Average over 100 episodes: 95.82\n",
      "Episode 478 Reward: 156.0 Average over 100 episodes: 96.4\n",
      "Episode 479 Reward: 137.0 Average over 100 episodes: 97.23\n",
      "Episode 480 Reward: 158.0 Average over 100 episodes: 97.2\n",
      "Episode 481 Reward: 132.0 Average over 100 episodes: 97.89\n",
      "Episode 482 Reward: 127.0 Average over 100 episodes: 98.85\n",
      "Episode 483 Reward: 172.0 Average over 100 episodes: 100.25\n",
      "Episode 484 Reward: 79.0 Average over 100 episodes: 100.11\n",
      "Episode 485 Reward: 234.0 Average over 100 episodes: 101.95\n",
      "Episode 486 Reward: 124.0 Average over 100 episodes: 102.6\n",
      "Episode 487 Reward: 112.0 Average over 100 episodes: 103.17\n",
      "Episode 488 Reward: 122.0 Average over 100 episodes: 103.98\n",
      "Episode 489 Reward: 57.0 Average over 100 episodes: 103.47\n",
      "Episode 490 Reward: 107.0 Average over 100 episodes: 103.84\n",
      "Episode 491 Reward: 126.0 Average over 100 episodes: 103.56\n",
      "Episode 492 Reward: 134.0 Average over 100 episodes: 104.61\n",
      "Episode 493 Reward: 183.0 Average over 100 episodes: 105.57\n",
      "Episode 494 Reward: 182.0 Average over 100 episodes: 107.08\n",
      "Episode 495 Reward: 50.0 Average over 100 episodes: 107.11\n",
      "Episode 496 Reward: 142.0 Average over 100 episodes: 107.86\n",
      "Episode 497 Reward: 145.0 Average over 100 episodes: 107.58\n",
      "Episode 498 Reward: 84.0 Average over 100 episodes: 108.0\n",
      "Episode 499 Reward: 193.0 Average over 100 episodes: 108.7\n",
      "Episode 500 Reward: 216.0 Average over 100 episodes: 110.52\n",
      "Episode 501 Reward: 112.0 Average over 100 episodes: 110.01\n",
      "Episode 502 Reward: 462.0 Average over 100 episodes: 114.13\n",
      "Episode 503 Reward: 187.0 Average over 100 episodes: 115.51\n",
      "Episode 504 Reward: 111.0 Average over 100 episodes: 116.45\n",
      "Episode 505 Reward: 128.0 Average over 100 episodes: 117.15\n",
      "Episode 506 Reward: 209.0 Average over 100 episodes: 118.72\n",
      "Episode 507 Reward: 141.0 Average over 100 episodes: 118.34\n",
      "Episode 508 Reward: 108.0 Average over 100 episodes: 118.84\n",
      "Episode 509 Reward: 164.0 Average over 100 episodes: 120.08\n",
      "Episode 510 Reward: 157.0 Average over 100 episodes: 121.2\n",
      "Episode 511 Reward: 248.0 Average over 100 episodes: 123.15\n",
      "Episode 512 Reward: 76.0 Average over 100 episodes: 122.54\n",
      "Episode 513 Reward: 116.0 Average over 100 episodes: 123.15\n",
      "Episode 514 Reward: 211.0 Average over 100 episodes: 124.07\n",
      "Episode 515 Reward: 176.0 Average over 100 episodes: 125.27\n",
      "Episode 516 Reward: 113.0 Average over 100 episodes: 125.58\n",
      "Episode 517 Reward: 179.0 Average over 100 episodes: 126.57\n",
      "Episode 518 Reward: 157.0 Average over 100 episodes: 127.84\n",
      "Episode 519 Reward: 181.0 Average over 100 episodes: 128.97\n",
      "Episode 520 Reward: 154.0 Average over 100 episodes: 129.37\n",
      "Episode 521 Reward: 306.0 Average over 100 episodes: 131.59\n",
      "Episode 522 Reward: 137.0 Average over 100 episodes: 131.76\n",
      "Episode 523 Reward: 138.0 Average over 100 episodes: 132.62\n",
      "Episode 524 Reward: 309.0 Average over 100 episodes: 135.23\n",
      "Episode 525 Reward: 161.0 Average over 100 episodes: 136.13\n",
      "Episode 526 Reward: 281.0 Average over 100 episodes: 138.41\n",
      "Episode 527 Reward: 134.0 Average over 100 episodes: 137.71\n",
      "Episode 528 Reward: 118.0 Average over 100 episodes: 137.94\n",
      "Episode 529 Reward: 216.0 Average over 100 episodes: 139.49\n",
      "Episode 530 Reward: 254.0 Average over 100 episodes: 141.07\n",
      "Episode 531 Reward: 196.0 Average over 100 episodes: 142.42\n",
      "Episode 532 Reward: 264.0 Average over 100 episodes: 143.59\n",
      "Episode 533 Reward: 289.0 Average over 100 episodes: 145.83\n",
      "Episode 534 Reward: 227.0 Average over 100 episodes: 147.01\n",
      "Episode 535 Reward: 128.0 Average over 100 episodes: 147.32\n",
      "Episode 536 Reward: 175.0 Average over 100 episodes: 148.25\n",
      "Episode 537 Reward: 269.0 Average over 100 episodes: 150.14\n",
      "Episode 538 Reward: 126.0 Average over 100 episodes: 150.59\n",
      "Episode 539 Reward: 189.0 Average over 100 episodes: 151.99\n",
      "Episode 540 Reward: 115.0 Average over 100 episodes: 151.25\n",
      "Episode 541 Reward: 275.0 Average over 100 episodes: 153.51\n",
      "Episode 542 Reward: 107.0 Average over 100 episodes: 153.87\n",
      "Episode 543 Reward: 146.0 Average over 100 episodes: 153.02\n",
      "Episode 544 Reward: 226.0 Average over 100 episodes: 154.4\n",
      "Episode 545 Reward: 229.0 Average over 100 episodes: 155.69\n",
      "Episode 546 Reward: 125.0 Average over 100 episodes: 155.19\n",
      "Episode 547 Reward: 107.0 Average over 100 episodes: 155.49\n",
      "Episode 548 Reward: 257.0 Average over 100 episodes: 157.45\n",
      "Episode 549 Reward: 221.0 Average over 100 episodes: 158.63\n",
      "Episode 550 Reward: 238.0 Average over 100 episodes: 160.12\n",
      "Episode 551 Reward: 264.0 Average over 100 episodes: 161.54\n",
      "Episode 552 Reward: 265.0 Average over 100 episodes: 162.75\n",
      "Episode 553 Reward: 175.0 Average over 100 episodes: 162.3\n",
      "Episode 554 Reward: 123.0 Average over 100 episodes: 162.27\n",
      "Episode 555 Reward: 200.0 Average over 100 episodes: 163.11\n",
      "Episode 556 Reward: 312.0 Average over 100 episodes: 164.91\n",
      "Episode 557 Reward: 182.0 Average over 100 episodes: 165.41\n",
      "Episode 558 Reward: 105.0 Average over 100 episodes: 165.58\n",
      "Episode 559 Reward: 147.0 Average over 100 episodes: 166.06\n",
      "Episode 560 Reward: 303.0 Average over 100 episodes: 167.99\n",
      "Episode 561 Reward: 134.0 Average over 100 episodes: 168.32\n",
      "Episode 562 Reward: 280.0 Average over 100 episodes: 169.73\n",
      "Episode 563 Reward: 321.0 Average over 100 episodes: 171.52\n",
      "Episode 564 Reward: 224.0 Average over 100 episodes: 172.87\n",
      "Episode 565 Reward: 133.0 Average over 100 episodes: 172.92\n",
      "Episode 566 Reward: 234.0 Average over 100 episodes: 174.54\n",
      "Episode 567 Reward: 156.0 Average over 100 episodes: 173.6\n",
      "Episode 568 Reward: 222.0 Average over 100 episodes: 175.39\n",
      "Episode 569 Reward: 178.0 Average over 100 episodes: 175.29\n",
      "Episode 570 Reward: 187.0 Average over 100 episodes: 175.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 571 Reward: 125.0 Average over 100 episodes: 175.82\n",
      "Episode 572 Reward: 192.0 Average over 100 episodes: 175.88\n",
      "Episode 573 Reward: 174.0 Average over 100 episodes: 175.98\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c1b3263b8055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mbaseline_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0madvantage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_discounted_return\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbaseline_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mvalue_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_discounted_return\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             feed_dict = {policy.state: transition.state, policy.R_t: advantage,\n",
      "\u001b[1;32m<ipython-input-8-c1b3263b8055>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, state, target, sess)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DRLEx2\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DRLEx2\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DRLEx2\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DRLEx2\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DRLEx2\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DRLEx2\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import datetime as dt\n",
    "from tensorboard import summary as summary_lib\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class ValueEstimator():\n",
    "    \"\"\"\n",
    "    Value Function approximator.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_size, learning_rate=0.1, scope=\"value_estimator\"):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.state = tf.placeholder(tf.int32, [state_size], \"state\")\n",
    "            self.target = tf.placeholder(dtype=tf.float32, name=\"target\")\n",
    "\n",
    "            # This is just table lookup estimator\n",
    "            state_one_hot = tf.one_hot(self.state, int(state_size))\n",
    "            self.output_layer = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(state_one_hot, 0),\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "\n",
    "            self.value_estimate = tf.squeeze(self.output_layer)\n",
    "            self.loss = tf.squared_difference(self.value_estimate, self.target)\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(\n",
    "                self.loss, global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "    def predict(self, state, sess=None):\n",
    "        state = state.reshape(-1)\n",
    "        sess = sess or tf.get_default_session()\n",
    "        return sess.run(self.value_estimate, {self.state: state})\n",
    "\n",
    "    def update(self, state, target, sess=None):\n",
    "        state = state.reshape(-1)\n",
    "\n",
    "        sess = sess or tf.get_default_session()\n",
    "        feed_dict = {self.state: state, self.target: target}\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class PolicyNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='policy_network'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            self.state = tf.placeholder(tf.float32, [None, self.state_size], name=\"state\")\n",
    "            self.action = tf.placeholder(tf.int32, [self.action_size], name=\"action\")\n",
    "            self.R_t = tf.placeholder(tf.float32, name=\"total_rewards\")\n",
    "\n",
    "            self.W1 = tf.get_variable(\"W1\", [self.state_size, 12],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            self.b1 = tf.get_variable(\"b1\", [12], initializer=tf.zeros_initializer())\n",
    "            self.W2 = tf.get_variable(\"W2\", [12, self.action_size],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            self.b2 = tf.get_variable(\"b2\", [self.action_size], initializer=tf.zeros_initializer())\n",
    "\n",
    "            self.Z1 = tf.add(tf.matmul(self.state, self.W1), self.b1)\n",
    "            self.A1 = tf.nn.relu(self.Z1)\n",
    "            self.output = tf.add(tf.matmul(self.A1, self.W2), self.b2)\n",
    "\n",
    "            # Softmax probability distribution over actions\n",
    "            self.actions_distribution = tf.squeeze(tf.nn.softmax(self.output))\n",
    "            # Loss with negative log probability\n",
    "            self.neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.output, labels=self.action)\n",
    "            self.loss = tf.reduce_mean(self.neg_log_prob * self.R_t)\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "state_size = 4\n",
    "action_size = env.action_space.n\n",
    "\n",
    "max_episodes = 5000\n",
    "max_steps = 501\n",
    "discount_factor = 0.99\n",
    "learning_rate = 0.0004\n",
    "\n",
    "render = False\n",
    "\n",
    "# Initialize the policy network\n",
    "tf.reset_default_graph()\n",
    "policy = PolicyNetwork(state_size, action_size, learning_rate)\n",
    "value_estimator = ValueEstimator(state_size)\n",
    "\n",
    "LOGDIR = './TensorBoard/Q2' + f\"/DQLearning_{dt.datetime.now().strftime('%d%m%Y%H%M')}\"\n",
    "# Start training the agent with REINFORCE algorithm\n",
    "with tf.Session() as sess, tf.summary.FileWriter(LOGDIR) as tb_logger:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    solved = False\n",
    "    Transition = collections.namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    episode_rewards = np.zeros(max_episodes)\n",
    "    average_rewards = 0.0\n",
    "    step_done = 0\n",
    "#     step = tf.placeholder(tf.int32)\n",
    "#     tf.summary.scalar('reward', step)\n",
    "#     summaries = tf.summary.merge_all()\n",
    "    sliding_avg = collections.deque(maxlen=100)\n",
    "    # step_done = tf.get_variable('step_done', shape=[])\n",
    "    i = 0\n",
    "    for episode in range(max_episodes):\n",
    "        state = env.reset()\n",
    "        state = state.reshape([1, state_size])\n",
    "        episode_transitions = []\n",
    "\n",
    "        for step in range(max_steps):\n",
    "\n",
    "            actions_distribution = sess.run(policy.actions_distribution, {policy.state: state})\n",
    "            action = np.random.choice(np.arange(len(actions_distribution)), p=actions_distribution)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = next_state.reshape([1, state_size])\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            action_one_hot = np.zeros(action_size)\n",
    "            action_one_hot[action] = 1\n",
    "            episode_transitions.append(\n",
    "                    Transition(state=state, action=action_one_hot, reward=reward, next_state=next_state, done=done))\n",
    "            episode_rewards[episode] += reward\n",
    "\n",
    "            if done:\n",
    "                step_done = step + 1\n",
    "                sliding_avg.append(step_done)\n",
    "                if episode > 98:\n",
    "                    # Check if solved\n",
    "                    average_rewards = np.mean(episode_rewards[(episode - 99):episode + 1])\n",
    "                print(\"Episode {} Reward: {} Average over 100 episodes: {}\".format(episode, episode_rewards[episode],\n",
    "                                                                                   round(average_rewards, 2)))\n",
    "                if average_rewards > 475:\n",
    "                    print(' Solved at episode: ' + str(episode))\n",
    "                    solved = True\n",
    "                break\n",
    "            state = next_state\n",
    "\n",
    "        if solved:\n",
    "            break\n",
    "        avg_loss = 0.0\n",
    "        # Compute Rt for each time-step t and update the network's weights\n",
    "        for t, transition in enumerate(episode_transitions):\n",
    "            total_discounted_return = sum(\n",
    "                discount_factor ** i * t.reward for i, t in enumerate(episode_transitions[t:]))  # Rt\n",
    "\n",
    "            baseline_value = value_estimator.predict(transition.state)\n",
    "            advantage = total_discounted_return - baseline_value\n",
    "            value_estimator.update(transition.state, total_discounted_return)\n",
    "\n",
    "            feed_dict = {policy.state: transition.state, policy.R_t: advantage,\n",
    "                         policy.action: transition.action}\n",
    "            _, loss = sess.run([policy.optimizer, policy.loss], feed_dict)\n",
    "            avg_loss += loss\n",
    "\n",
    "#         tb_logger.add_summary(step_done, episode)\n",
    "#         tb_logger.add_summary(avg_loss / step_done, episode)\n",
    "#         tb_logger.add_summary(sum(sliding_avg) / len(sliding_avg), episode)\n",
    "#         tf.summary.scalar('reward', step_done, step=episode)\n",
    "#         tf.summary.scalar('avg loss', avg_loss / step_done, step=episode)\n",
    "#         tf.summary.scalar('reward_avg_100_eps', sum(sliding_avg) / len(sliding_avg), step=episode)\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag='reward',\n",
    "                                                     simple_value=step_done),\n",
    "                                   tf.Summary.Value(tag='avg_loss',\n",
    "                                                     simple_value=avg_loss / step_done),\n",
    "                                   tf.Summary.Value(tag='reward_avg_100_eps',\n",
    "                                                     simple_value=sum(sliding_avg) / len(sliding_avg))])\n",
    "        tb_logger.add_summary(summary, episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
